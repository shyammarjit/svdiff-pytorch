The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
03/26/2024 03:11:54 - INFO - __main__ - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

{'clip_sample_range', 'variance_type', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'scaling_factor'} was not found in config. Values will be initialized to default values.
{'only_cross_attention', 'dual_cross_attention', 'time_embedding_type', 'num_class_embeds', 'timestep_post_act', 'conv_in_kernel', 'projection_class_embeddings_input_dim', 'mid_block_type', 'conv_out_kernel', 'use_linear_projection', 'class_embed_type', 'time_cond_proj_dim', 'resnet_time_scale_shift', 'upcast_attention'} was not found in config. Values will be initialized to default values.
{'only_cross_attention', 'dual_cross_attention', 'time_embedding_type', 'num_class_embeds', 'timestep_post_act', 'conv_in_kernel', 'projection_class_embeddings_input_dim', 'mid_block_type', 'conv_out_kernel', 'use_linear_projection', 'class_embed_type', 'time_cond_proj_dim', 'resnet_time_scale_shift', 'upcast_attention'} was not found in config. Values will be initialized to default values.
03/26/2024 03:12:00 - INFO - __main__ - ***** Running training *****
03/26/2024 03:12:00 - INFO - __main__ -   Num examples = 200
03/26/2024 03:12:00 - INFO - __main__ -   Num batches each epoch = 200
03/26/2024 03:12:00 - INFO - __main__ -   Num Epochs = 5
03/26/2024 03:12:00 - INFO - __main__ -   Instantaneous batch size per device = 1
03/26/2024 03:12:00 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1
03/26/2024 03:12:00 - INFO - __main__ -   Gradient Accumulation steps = 1
03/26/2024 03:12:00 - INFO - __main__ -   Total optimization steps = 1000
Number of Trainable Parameters: 0.28 M
  0%|          | 0/1000 [00:00<?, ?it/s]Steps:   0%|          | 0/1000 [00:00<?, ?it/s]/home/shyam/miniconda3/envs/svdiff/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Steps:   0%|          | 1/1000 [00:26<7:27:59, 26.91s/it]Steps:   0%|          | 1/1000 [00:26<7:27:59, 26.91s/it, loss=0.514, lr=0.001, lr_1d=1e-6]Steps:   0%|          | 2/1000 [00:28<3:21:51, 12.14s/it, loss=0.514, lr=0.001, lr_1d=1e-6]Steps:   0%|          | 2/1000 [00:28<3:21:51, 12.14s/it, loss=0.151, lr=0.001, lr_1d=1e-6]Steps:   0%|          | 3/1000 [00:30<2:02:55,  7.40s/it, loss=0.151, lr=0.001, lr_1d=1e-6]Steps:   0%|          | 3/1000 [00:30<2:02:55,  7.40s/it, loss=0.831, lr=0.001, lr_1d=1e-6]Steps:   0%|          | 4/1000 [00:32<1:25:49,  5.17s/it, loss=0.831, lr=0.001, lr_1d=1e-6]Steps:   0%|          | 4/1000 [00:32<1:25:49,  5.17s/it, loss=0.0469, lr=0.001, lr_1d=1e-6]Steps:   0%|          | 5/1000 [00:33<1:05:17,  3.94s/it, loss=0.0469, lr=0.001, lr_1d=1e-6]Steps:   0%|          | 5/1000 [00:33<1:05:17,  3.94s/it, loss=0.198, lr=0.001, lr_1d=1e-6] Steps:   1%|          | 6/1000 [00:35<52:57,  3.20s/it, loss=0.198, lr=0.001, lr_1d=1e-6]  Steps:   1%|          | 6/1000 [00:35<52:57,  3.20s/it, loss=0.513, lr=0.001, lr_1d=1e-6]Steps:   1%|          | 7/1000 [00:37<45:16,  2.74s/it, loss=0.513, lr=0.001, lr_1d=1e-6]Steps:   1%|          | 7/1000 [00:37<45:16,  2.74s/it, loss=0.0368, lr=0.001, lr_1d=1e-6]Steps:   1%|          | 8/1000 [00:39<40:05,  2.42s/it, loss=0.0368, lr=0.001, lr_1d=1e-6]Steps:   1%|          | 8/1000 [00:39<40:05,  2.42s/it, loss=0.276, lr=0.001, lr_1d=1e-6] Steps:   1%|          | 9/1000 [00:41<36:39,  2.22s/it, loss=0.276, lr=0.001, lr_1d=1e-6]Steps:   1%|          | 9/1000 [00:41<36:39,  2.22s/it, loss=0.386, lr=0.001, lr_1d=1e-6]Steps:   1%|          | 10/1000 [00:42<34:26,  2.09s/it, loss=0.386, lr=0.001, lr_1d=1e-6]Steps:   1%|          | 10/1000 [00:42<34:26,  2.09s/it, loss=0.26, lr=0.001, lr_1d=1e-6] Steps:   1%|          | 11/1000 [00:44<32:45,  1.99s/it, loss=0.26, lr=0.001, lr_1d=1e-6]Steps:   1%|          | 11/1000 [00:44<32:45,  1.99s/it, loss=0.0989, lr=0.001, lr_1d=1e-6]Steps:   1%|          | 12/1000 [00:46<31:38,  1.92s/it, loss=0.0989, lr=0.001, lr_1d=1e-6]Steps:   1%|          | 12/1000 [00:46<31:38,  1.92s/it, loss=0.0143, lr=0.001, lr_1d=1e-6]Steps:   1%|▏         | 13/1000 [00:48<30:47,  1.87s/it, loss=0.0143, lr=0.001, lr_1d=1e-6]Steps:   1%|▏         | 13/1000 [00:48<30:47,  1.87s/it, loss=0.527, lr=0.001, lr_1d=1e-6] Steps:   1%|▏         | 14/1000 [00:49<30:18,  1.84s/it, loss=0.527, lr=0.001, lr_1d=1e-6]Steps:   1%|▏         | 14/1000 [00:49<30:18,  1.84s/it, loss=0.0347, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 15/1000 [00:51<29:57,  1.83s/it, loss=0.0347, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 15/1000 [00:51<29:57,  1.83s/it, loss=0.0562, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 16/1000 [00:53<29:37,  1.81s/it, loss=0.0562, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 16/1000 [00:53<29:37,  1.81s/it, loss=0.138, lr=0.001, lr_1d=1e-6] Steps:   2%|▏         | 17/1000 [00:55<29:24,  1.80s/it, loss=0.138, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 17/1000 [00:55<29:24,  1.80s/it, loss=0.269, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 18/1000 [00:57<29:20,  1.79s/it, loss=0.269, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 18/1000 [00:57<29:20,  1.79s/it, loss=0.105, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 19/1000 [00:59<30:56,  1.89s/it, loss=0.105, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 19/1000 [00:59<30:56,  1.89s/it, loss=0.0838, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 20/1000 [01:01<32:01,  1.96s/it, loss=0.0838, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 20/1000 [01:01<32:01,  1.96s/it, loss=0.285, lr=0.001, lr_1d=1e-6] Steps:   2%|▏         | 21/1000 [01:03<33:47,  2.07s/it, loss=0.285, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 21/1000 [01:03<33:47,  2.07s/it, loss=0.0212, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 22/1000 [01:05<34:48,  2.14s/it, loss=0.0212, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 22/1000 [01:05<34:48,  2.14s/it, loss=0.828, lr=0.001, lr_1d=1e-6] Steps:   2%|▏         | 23/1000 [01:07<33:07,  2.03s/it, loss=0.828, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 23/1000 [01:07<33:07,  2.03s/it, loss=0.42, lr=0.001, lr_1d=1e-6] Steps:   2%|▏         | 24/1000 [01:09<31:54,  1.96s/it, loss=0.42, lr=0.001, lr_1d=1e-6]Steps:   2%|▏         | 24/1000 [01:09<31:54,  1.96s/it, loss=0.159, lr=0.001, lr_1d=1e-6]Steps:   2%|▎         | 25/1000 [01:11<31:06,  1.91s/it, loss=0.159, lr=0.001, lr_1d=1e-6]Steps:   2%|▎         | 25/1000 [01:11<31:06,  1.91s/it, loss=0.513, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 26/1000 [01:13<30:31,  1.88s/it, loss=0.513, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 26/1000 [01:13<30:31,  1.88s/it, loss=0.175, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 27/1000 [01:14<30:05,  1.86s/it, loss=0.175, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 27/1000 [01:14<30:05,  1.86s/it, loss=0.145, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 28/1000 [01:16<29:50,  1.84s/it, loss=0.145, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 28/1000 [01:16<29:50,  1.84s/it, loss=0.913, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 29/1000 [01:18<29:37,  1.83s/it, loss=0.913, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 29/1000 [01:18<29:37,  1.83s/it, loss=0.93, lr=0.001, lr_1d=1e-6] Steps:   3%|▎         | 30/1000 [01:20<29:25,  1.82s/it, loss=0.93, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 30/1000 [01:20<29:25,  1.82s/it, loss=0.448, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 31/1000 [01:22<29:17,  1.81s/it, loss=0.448, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 31/1000 [01:22<29:17,  1.81s/it, loss=0.201, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 32/1000 [01:23<29:12,  1.81s/it, loss=0.201, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 32/1000 [01:23<29:12,  1.81s/it, loss=0.42, lr=0.001, lr_1d=1e-6] Steps:   3%|▎         | 33/1000 [01:25<29:06,  1.81s/it, loss=0.42, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 33/1000 [01:25<29:06,  1.81s/it, loss=0.336, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 34/1000 [01:27<29:02,  1.80s/it, loss=0.336, lr=0.001, lr_1d=1e-6]Steps:   3%|▎         | 34/1000 [01:27<29:02,  1.80s/it, loss=0.00847, lr=0.001, lr_1d=1e-6]Steps:   4%|▎         | 35/1000 [01:29<29:05,  1.81s/it, loss=0.00847, lr=0.001, lr_1d=1e-6]Steps:   4%|▎         | 35/1000 [01:29<29:05,  1.81s/it, loss=0.359, lr=0.001, lr_1d=1e-6]  Steps:   4%|▎         | 36/1000 [01:31<29:00,  1.81s/it, loss=0.359, lr=0.001, lr_1d=1e-6]Steps:   4%|▎         | 36/1000 [01:31<29:00,  1.81s/it, loss=0.149, lr=0.001, lr_1d=1e-6]Steps:   4%|▎         | 37/1000 [01:32<28:58,  1.81s/it, loss=0.149, lr=0.001, lr_1d=1e-6]Steps:   4%|▎         | 37/1000 [01:32<28:58,  1.81s/it, loss=1.18, lr=0.001, lr_1d=1e-6] Steps:   4%|▍         | 38/1000 [01:34<28:58,  1.81s/it, loss=1.18, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 38/1000 [01:34<28:58,  1.81s/it, loss=1.19, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 39/1000 [01:36<28:48,  1.80s/it, loss=1.19, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 39/1000 [01:36<28:48,  1.80s/it, loss=0.146, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 40/1000 [01:38<28:53,  1.81s/it, loss=0.146, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 40/1000 [01:38<28:53,  1.81s/it, loss=0.747, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 41/1000 [01:40<28:50,  1.80s/it, loss=0.747, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 41/1000 [01:40<28:50,  1.80s/it, loss=0.241, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 42/1000 [01:41<28:52,  1.81s/it, loss=0.241, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 42/1000 [01:41<28:52,  1.81s/it, loss=0.0916, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 43/1000 [01:43<29:33,  1.85s/it, loss=0.0916, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 43/1000 [01:43<29:33,  1.85s/it, loss=0.675, lr=0.001, lr_1d=1e-6] Steps:   4%|▍         | 44/1000 [01:45<29:11,  1.83s/it, loss=0.675, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 44/1000 [01:45<29:11,  1.83s/it, loss=0.0201, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 45/1000 [01:47<29:03,  1.83s/it, loss=0.0201, lr=0.001, lr_1d=1e-6]Steps:   4%|▍         | 45/1000 [01:47<29:03,  1.83s/it, loss=0.186, lr=0.001, lr_1d=1e-6] Steps:   5%|▍         | 46/1000 [01:49<29:03,  1.83s/it, loss=0.186, lr=0.001, lr_1d=1e-6]Steps:   5%|▍         | 46/1000 [01:49<29:03,  1.83s/it, loss=0.216, lr=0.001, lr_1d=1e-6]Steps:   5%|▍         | 47/1000 [01:51<28:55,  1.82s/it, loss=0.216, lr=0.001, lr_1d=1e-6]Steps:   5%|▍         | 47/1000 [01:51<28:55,  1.82s/it, loss=0.0192, lr=0.001, lr_1d=1e-6]Steps:   5%|▍         | 48/1000 [01:52<28:50,  1.82s/it, loss=0.0192, lr=0.001, lr_1d=1e-6]Steps:   5%|▍         | 48/1000 [01:52<28:50,  1.82s/it, loss=0.255, lr=0.001, lr_1d=1e-6] Steps:   5%|▍         | 49/1000 [01:54<28:46,  1.82s/it, loss=0.255, lr=0.001, lr_1d=1e-6]Steps:   5%|▍         | 49/1000 [01:54<28:46,  1.82s/it, loss=0.244, lr=0.001, lr_1d=1e-6]Steps:   5%|▌         | 50/1000 [01:56<28:41,  1.81s/it, loss=0.244, lr=0.001, lr_1d=1e-6]Steps:   5%|▌         | 50/1000 [01:56<28:41,  1.81s/it, loss=0.201, lr=0.001, lr_1d=1e-6]Steps:   5%|▌         | 51/1000 [01:58<28:41,  1.81s/it, loss=0.201, lr=0.001, lr_1d=1e-6]Steps:   5%|▌         | 51/1000 [01:58<28:41,  1.81s/it, loss=0.279, lr=0.001, lr_1d=1e-6]Steps:   5%|▌         | 52/1000 [02:00<28:38,  1.81s/it, loss=0.279, lr=0.001, lr_1d=1e-6]Steps:   5%|▌         | 52/1000 [02:00<28:38,  1.81s/it, loss=0.499, lr=0.001, lr_1d=1e-6]Steps:   5%|▌         | 53/1000 [02:01<28:35,  1.81s/it, loss=0.499, lr=0.001, lr_1d=1e-6]Steps:   5%|▌         | 53/1000 [02:01<28:35,  1.81s/it, loss=0.126, lr=0.001, lr_1d=1e-6]Steps:   5%|▌         | 54/1000 [02:03<28:33,  1.81s/it, loss=0.126, lr=0.001, lr_1d=1e-6]Steps:   5%|▌         | 54/1000 [02:03<28:33,  1.81s/it, loss=0.531, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 55/1000 [02:05<28:32,  1.81s/it, loss=0.531, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 55/1000 [02:05<28:32,  1.81s/it, loss=0.288, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 56/1000 [02:07<28:29,  1.81s/it, loss=0.288, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 56/1000 [02:07<28:29,  1.81s/it, loss=0.235, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 57/1000 [02:09<28:39,  1.82s/it, loss=0.235, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 57/1000 [02:09<28:39,  1.82s/it, loss=0.414, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 58/1000 [02:11<28:35,  1.82s/it, loss=0.414, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 58/1000 [02:11<28:35,  1.82s/it, loss=0.0419, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 59/1000 [02:12<28:33,  1.82s/it, loss=0.0419, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 59/1000 [02:12<28:33,  1.82s/it, loss=0.27, lr=0.001, lr_1d=1e-6]  Steps:   6%|▌         | 60/1000 [02:14<28:34,  1.82s/it, loss=0.27, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 60/1000 [02:14<28:34,  1.82s/it, loss=0.162, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 61/1000 [02:16<28:29,  1.82s/it, loss=0.162, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 61/1000 [02:16<28:29,  1.82s/it, loss=0.0462, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 62/1000 [02:18<28:27,  1.82s/it, loss=0.0462, lr=0.001, lr_1d=1e-6]Steps:   6%|▌         | 62/1000 [02:18<28:27,  1.82s/it, loss=0.972, lr=0.001, lr_1d=1e-6] Steps:   6%|▋         | 63/1000 [02:20<28:28,  1.82s/it, loss=0.972, lr=0.001, lr_1d=1e-6]Steps:   6%|▋         | 63/1000 [02:20<28:28,  1.82s/it, loss=0.133, lr=0.001, lr_1d=1e-6]Steps:   6%|▋         | 64/1000 [02:22<28:28,  1.83s/it, loss=0.133, lr=0.001, lr_1d=1e-6]Steps:   6%|▋         | 64/1000 [02:22<28:28,  1.83s/it, loss=0.208, lr=0.001, lr_1d=1e-6]Steps:   6%|▋         | 65/1000 [02:23<28:27,  1.83s/it, loss=0.208, lr=0.001, lr_1d=1e-6]Steps:   6%|▋         | 65/1000 [02:23<28:27,  1.83s/it, loss=0.342, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 66/1000 [02:25<28:35,  1.84s/it, loss=0.342, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 66/1000 [02:25<28:35,  1.84s/it, loss=0.0637, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 67/1000 [02:27<28:30,  1.83s/it, loss=0.0637, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 67/1000 [02:27<28:30,  1.83s/it, loss=0.26, lr=0.001, lr_1d=1e-6]  Steps:   7%|▋         | 68/1000 [02:29<28:27,  1.83s/it, loss=0.26, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 68/1000 [02:29<28:27,  1.83s/it, loss=0.0484, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 69/1000 [02:31<28:26,  1.83s/it, loss=0.0484, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 69/1000 [02:31<28:26,  1.83s/it, loss=0.459, lr=0.001, lr_1d=1e-6] Steps:   7%|▋         | 70/1000 [02:33<28:29,  1.84s/it, loss=0.459, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 70/1000 [02:33<28:29,  1.84s/it, loss=0.145, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 71/1000 [02:34<28:26,  1.84s/it, loss=0.145, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 71/1000 [02:34<28:26,  1.84s/it, loss=0.256, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 72/1000 [02:36<28:18,  1.83s/it, loss=0.256, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 72/1000 [02:36<28:18,  1.83s/it, loss=0.082, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 73/1000 [02:38<28:15,  1.83s/it, loss=0.082, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 73/1000 [02:38<28:15,  1.83s/it, loss=0.235, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 74/1000 [02:40<28:11,  1.83s/it, loss=0.235, lr=0.001, lr_1d=1e-6]Steps:   7%|▋         | 74/1000 [02:40<28:11,  1.83s/it, loss=0.0304, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 75/1000 [02:42<28:14,  1.83s/it, loss=0.0304, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 75/1000 [02:42<28:14,  1.83s/it, loss=0.579, lr=0.001, lr_1d=1e-6] Steps:   8%|▊         | 76/1000 [02:43<28:03,  1.82s/it, loss=0.579, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 76/1000 [02:43<28:03,  1.82s/it, loss=0.406, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 77/1000 [02:45<28:04,  1.82s/it, loss=0.406, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 77/1000 [02:45<28:04,  1.82s/it, loss=0.152, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 78/1000 [02:47<27:56,  1.82s/it, loss=0.152, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 78/1000 [02:47<27:56,  1.82s/it, loss=0.365, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 79/1000 [02:49<28:03,  1.83s/it, loss=0.365, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 79/1000 [02:49<28:03,  1.83s/it, loss=0.204, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 80/1000 [02:51<28:01,  1.83s/it, loss=0.204, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 80/1000 [02:51<28:01,  1.83s/it, loss=0.247, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 81/1000 [02:53<27:58,  1.83s/it, loss=0.247, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 81/1000 [02:53<27:58,  1.83s/it, loss=0.371, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 82/1000 [02:54<27:56,  1.83s/it, loss=0.371, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 82/1000 [02:54<27:56,  1.83s/it, loss=0.276, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 83/1000 [02:56<27:53,  1.82s/it, loss=0.276, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 83/1000 [02:56<27:53,  1.82s/it, loss=0.562, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 84/1000 [02:58<27:49,  1.82s/it, loss=0.562, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 84/1000 [02:58<27:49,  1.82s/it, loss=0.72, lr=0.001, lr_1d=1e-6] Steps:   8%|▊         | 85/1000 [03:00<27:48,  1.82s/it, loss=0.72, lr=0.001, lr_1d=1e-6]Steps:   8%|▊         | 85/1000 [03:00<27:48,  1.82s/it, loss=0.236, lr=0.001, lr_1d=1e-6]Steps:   9%|▊         | 86/1000 [03:02<27:45,  1.82s/it, loss=0.236, lr=0.001, lr_1d=1e-6]Steps:   9%|▊         | 86/1000 [03:02<27:45,  1.82s/it, loss=0.0963, lr=0.001, lr_1d=1e-6]Steps:   9%|▊         | 87/1000 [03:04<27:44,  1.82s/it, loss=0.0963, lr=0.001, lr_1d=1e-6]Steps:   9%|▊         | 87/1000 [03:04<27:44,  1.82s/it, loss=0.117, lr=0.001, lr_1d=1e-6] Steps:   9%|▉         | 88/1000 [03:05<27:37,  1.82s/it, loss=0.117, lr=0.001, lr_1d=1e-6]Steps:   9%|▉         | 88/1000 [03:05<27:37,  1.82s/it, loss=0.174, lr=0.001, lr_1d=1e-6]Steps:   9%|▉         | 89/1000 [03:07<27:37,  1.82s/it, loss=0.174, lr=0.001, lr_1d=1e-6]Steps:   9%|▉         | 89/1000 [03:07<27:37,  1.82s/it, loss=0.565, lr=0.001, lr_1d=1e-6]Steps:   9%|▉         | 90/1000 [03:09<27:29,  1.81s/it, loss=0.565, lr=0.001, lr_1d=1e-6]Steps:   9%|▉         | 90/1000 [03:09<27:29,  1.81s/it, loss=0.413, lr=0.001, lr_1d=1e-6]Steps:   9%|▉         | 91/1000 [03:11<27:31,  1.82s/it, loss=0.413, lr=0.001, lr_1d=1e-6]Steps:   9%|▉         | 91/1000 [03:11<27:31,  1.82s/it, loss=0.623, lr=0.001, lr_1d=1e-6]Steps:   9%|▉         | 92/1000 [03:13<27:34,  1.82s/it, loss=0.623, lr=0.001, lr_1d=1e-6]Steps:   9%|▉         | 92/1000 [03:13<27:34,  1.82s/it, loss=0.0241, lr=0.001, lr_1d=1e-6]Steps:   9%|▉         | 93/1000 [03:14<27:34,  1.82s/it, loss=0.0241, lr=0.001, lr_1d=1e-6]Steps:   9%|▉         | 93/1000 [03:14<27:34,  1.82s/it, loss=0.448, lr=0.001, lr_1d=1e-6] Steps:   9%|▉         | 94/1000 [03:16<27:31,  1.82s/it, loss=0.448, lr=0.001, lr_1d=1e-6]Steps:   9%|▉         | 94/1000 [03:16<27:31,  1.82s/it, loss=0.0106, lr=0.001, lr_1d=1e-6]Steps:  10%|▉         | 95/1000 [03:18<27:30,  1.82s/it, loss=0.0106, lr=0.001, lr_1d=1e-6]Steps:  10%|▉         | 95/1000 [03:18<27:30,  1.82s/it, loss=0.558, lr=0.001, lr_1d=1e-6] Steps:  10%|▉         | 96/1000 [03:20<27:30,  1.83s/it, loss=0.558, lr=0.001, lr_1d=1e-6]Steps:  10%|▉         | 96/1000 [03:20<27:30,  1.83s/it, loss=0.137, lr=0.001, lr_1d=1e-6]